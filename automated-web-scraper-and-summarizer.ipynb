{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Installing the necessary libraries","metadata":{}},{"cell_type":"code","source":"!pip install firecrawl-py\n!pip install mailjet_rest\n!pip install llama_index\n!pip install llama-index llama-index-llms-groq groq","metadata":{"_uuid":"52eee387-bdf7-419c-96c3-9552d06e9da4","_cell_guid":"cf323e0b-c911-4361-ae92-cd851251e2c4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport time\nimport re\nfrom firecrawl import FirecrawlApp\nfrom requests.exceptions import HTTPError\nfrom llama_index.llms.groq import Groq\nimport textwrap\nfrom mailjet_rest import Client\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run this cell\nThe user has to give input about search query, recipient email address and their name.","metadata":{}},{"cell_type":"code","source":"\n\n# Initialize the Groq LLM\nllm_groq = Groq(model=\"llama3-70b-8192\", api_key=\"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\") \n\n# Function to fetch search results\ndef fetch_search_results(query):\n    api_key = '6e7a28dfb535d1bd93af90c03765a36c43da33cd61154c59361c3bfa0f176db9'  \n    url = f\"https://serpapi.com/search?api_key={api_key}&q={query}\"\n    \n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        results = response.json()\n        return results.get('organic_results', [])[:2]  \n    else:\n        print(\"Error fetching results:\", response.status_code)\n        return []\n\n# Function to clean Website content\ndef clean_wikipedia_content(content):\n    if not isinstance(content, str):\n        content = str(content)\n        \n    cleaned_content = re.sub(r'\\[.*?\\]', '', content)  \n    cleaned_content = re.sub(r'https?://\\S+', '', cleaned_content)  \n    cleaned_content = re.sub(r'!\\(data:image/\\S+;base64,[^\\)]+\\)', '', cleaned_content)  \n    cleaned_content = re.sub(r'::+', ' ', cleaned_content)  \n    cleaned_content = re.sub(r'\\s+', ' ', cleaned_content)  \n    \n    return cleaned_content.strip()\n\n# Function to split content into chunks\ndef split_content_into_chunks(content, chunk_size=15000):\n    return textwrap.wrap(content, chunk_size)\n\n# Function to summarize each chunk with Groq\ndef summarize_with_groq(text):\n    prompt = f\"\"\"\n    Generate a summary of the text which explains everything in 200 words at maximum. Do not exceed this limit.\n    \n    Text: {text}\n    \"\"\"\n    \n    response = llm_groq.complete(prompt)\n    return response.text  \n\n# Function to scrape content from URLs with rate limit handling\ndef scrape_urls(urls, firecrawl):\n    all_summaries = []\n    \n    for url in urls:\n        while True:\n            try:\n                print(f\"Scraping {url}...\")\n                \n                # Scrape the URL and get the content\n                page_content = firecrawl.scrape_url(url=url, params={\"onlyMainContent\": True})\n                \n                # Ensure the content is a string\n                if not isinstance(page_content, str):\n                    page_content = str(page_content)\n                \n                # Clean the content\n                cleaned_content = clean_wikipedia_content(page_content)\n                \n                # Split the cleaned content into chunks\n                chunks = split_content_into_chunks(cleaned_content)\n                \n                # Summarize each chunk using Groq\n                chunk_summaries = [summarize_with_groq(chunk) for chunk in chunks]\n                \n                # Combine chunk summaries\n                combined_summary = \" \".join(chunk_summaries)\n                \n                # Add this URL's combined summary to the list of all summaries\n                all_summaries.append(combined_summary)\n                \n                # Print the URL's combined summary\n                print(f\"Summary from {url}:\")\n                print(combined_summary)\n                print(\"\\n\" + \"=\"*80 + \"\\n\")  \n                break  \n            \n            except HTTPError as e:\n                if e.response.status_code == 429:\n                    # Handle rate limit exceeded error\n                    reset_time = e.response.headers.get('Retry-After', 45) \n                    print(f\"Rate limit exceeded. Pausing for {reset_time} seconds...\")\n                    time.sleep(int(reset_time))  \n                else:\n                    print(f\"An error occurred: {e}\")\n                    break  \n\n    # Combine all URL summaries\n    large_text = \" \".join(all_summaries)\n    \n    # Create the prompt for the final summarization\n    final_prompt = f\"\"\"\n    Based on the following text, generate:\n    1. A title\n    2. An introduction\n    3. Five top subtopic titles\n    4. A short summary\n    5. A conclusion\n\n    Text: {large_text}\n    \"\"\"\n    \n    # Generate the final summary with Groq\n    final_summary = llm_groq.complete(final_prompt)\n    \n    # Print the final summary\n    print(\"Final Summary of All URLs:\")\n    print(final_summary)\n\n    return final_summary.text  \n\n# Function to send an email using Mailjet\ndef send_email_mailjet(subject, body, recipient, rec_name):\n    api_key = 'fd5ec7040540bf0b2ffe1f6d5bcc49aa'\n    api_secret = \"b0a5c161ba03369f3ed18c7ab530b52e\"\n    \n    mailjet = Client(auth=(api_key, api_secret), version='v3.1')\n    \n    data = {\n        'Messages': [\n            {\n                'From': {\n                    'Email': 'nrj.eea@gmail.com',\n                    'Name': 'Neeraj'\n                },\n                'To': [\n                    {\n                        'Email': recipient,\n                        'Name': rec_name\n                    }\n                ],\n                'Subject': subject,\n                'TextPart': body,\n                'HTMLPart': f\"<p>{body}</p>\" \n            }\n        ]\n    }\n    \n    result = mailjet.send.create(data=data)\n    print(result.status_code)\n    print(result.json())\n\n# Initialize the Firecrawl application with your API key\napi_key = \"fc-0d7421cf1f3c467aa17269df26a307e8\"  \nfirecrawl = FirecrawlApp(api_key=api_key)\n\n# Step 1: Fetch search results\nquery = input(\"Enter your search query: \")\nresults = fetch_search_results(query)\n\n# Step 2: Extract URLs from the search results\nurls = [result.get('link') for result in results if result.get('link')]\n\n# Step 3: Scrape content from the URLs\nfinal_summary = scrape_urls(urls, firecrawl)\n\n# Step 4: Send the final summary via email\nrecipient_email = input(\"Enter recipient email address: \")\nrec_name = input(\"Enter the name: \")\nsend_email_mailjet(\"Final Summary of Search Results\", final_summary, recipient_email, rec_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}